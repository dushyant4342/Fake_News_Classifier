# -*- coding: utf-8 -*-
"""Fake news classifier using LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EcLmIM8vICaVE6YWigfrBwwmusQlHyDH
"""

import pandas as pd
df=pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_fakenews.csv')

df.head()

df.shape

df.isnull().sum()

df=df.dropna()

X=df.drop('label', axis=1)

y=df['label']

X.shape

y.shape

import tensorflow as tf

tf.__version__

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense, Dropout # >0.5=fake, <0.5=not fake

#Vocabulary_size

voc_size=5000

#ONEHOT REPRESENTATION

messages=X.copy()

messages['title'][3:13]

messages.reset_index(inplace=True)    #because we have dropped na values

import nltk
import re                 #(regular expression)
from nltk.corpus import stopwords     #to remove spaces/words which are not importanat

nltk.download('stopwords')

df.head(10)

from nltk.stem.porter import PorterStemmer #
ps=PorterStemmer()
corpus=[]

for i in range (0,len(messages)):
  review=re.sub('[^a-zA-Z]', ' ', messages['title'][i])  #substitute all words except (a-z,A-Z) and substituting them by spaces.
  review=review.lower()
  review=review.split()

  review = [ps.stem(word) for word in review if not word in stopwords.words('english')] 
  review=' '.join(review)
  corpus.append(review)

corpus

onehot_rep=[one_hot(words,voc_size)for words in corpus]
onehot_rep

sent_length=20
embedded_docs = pad_sequences(onehot_rep, padding='pre', maxlen=sent_length)
print(embedded_docs)

embedded_docs.shape

#CREATING THE MODEL

embedding_vector_features=40
model=Sequential()
model.add(Embedding(voc_size,embedding_vector_features, input_length=sent_length))
model.add(Dropout(0.3))
model.add(LSTM(100))
model.add(Dropout(0.2))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

len(embedded_docs), y.shape

import numpy as np

X_final=np.array(embedded_docs)
X_final

y_final=np.array(y)

X_final.shape, y_final.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)

#NOW MODEL TRAINING

model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=10, batch_size=64 )

y_pred=model.predict_classes(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score

accuracy_score(y_test, y_pred)*100

confusion_matrix(y_test,y_pred) #[[TP FP]
                                 #[FN TN]]

